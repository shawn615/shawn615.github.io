<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Seunghyeon Seo</title>
  
  <meta name="author" content="Seunghyeon Seo">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üçÄ</text></svg>">
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-XV9FTV9E2Z"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-XV9FTV9E2Z');
</script>
	
<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Seunghyeon Seo</name>
              </p>
              <p>
		I'm a Ph.D. student at <a href="https://eng.snu.ac.kr/">College of Engineering in Seoul National University</a>, where I'm advised by Prof. <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a> in the <a href="http://mipal.snu.ac.kr/index.php/Main_Page">Machine Intelligence and Pattern Analysis Lab (MIPAL)</a>.
		Previously, I got my bachelor's degree from <a href="https://cals.snu.ac.kr/en">College of Agriculture and Life Sciences in SNU</a>, where I majored in Agricultural Economics.
              </p>
              <p>
                I'm interested in computer vision, machine learning, and neural rendering.
		Much of my interest is currently focused on the efficient training framework of NeRF and 3D-GS.
              </p>
<!-- 	      <p> -->
<!--                 <strong>Currently on the hunt for an internship! If you're interested, please don't hesitate to reach out. Thanks! üåü</strong> -->
<!--               </p> -->
              <p style="text-align:center">
                <a href="mailto:zzzlssh@snu.ac.kr">Email</a> &nbsp/&nbsp
                <a href="data/SeunghyeonSeo_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=LL9u-5IAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/shawn615/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/shawn615/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/SeunghyeonSeo.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/SeunghyeonSeo.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <!-- News Table Heading -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
            </td>
          </tr>
        </tbody></table>

        <!-- News Table Content -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:top">
              <ul>
                <p><strong>Apr. 2024:</strong> One paper is accepted to <a href="https://sites.google.com/view/elvm/">CVPR 2024 Workshop on Efficient Large Vision Models</a>. </p>
		<p><strong>Feb. 2024:</strong> I will be joining <a href="https://tech.facebook.com/reality-labs/">Meta Reality Labs</a> as a research scientist intern this summer. </p>
                <!-- Add more news items as needed -->
              </ul>
            </td>
          </tr>
        </tbody></table>
	      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		
<!--<tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()"  bgcolor="#ffffd0">-->
<!--  <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--    <div class="one">-->
<!--      <div class="two" id='dreamfusion_image'><video  width=100% height=100% muted autoplay loop>-->
<!--      <source src="images/dreamfusion.mp4" type="video/mp4">-->
<!--      Your browser does not support the video tag.-->
<!--      </video></div>-->
<!--      <img src='images/dreamfusion.jpg' width="160">-->
<!--    </div>-->
<!--    <script type="text/javascript">-->
<!--      function dreamfusion_start() {-->
<!--        document.getElementById('dreamfusion_image').style.opacity = "1";-->
<!--      }-->

<!--      function dreamfusion_stop() {-->
<!--        document.getElementById('dreamfusion_image').style.opacity = "0";-->
<!--      }-->
<!--      dreamfusion_stop()-->
<!--    </script>-->
<!--  </td>-->
<!--  <td style="padding:20px;width:75%;vertical-align:middle">-->
<!--    <a href="https://dreamfusion3d.github.io/">-->
<!--      <papertitle>DreamFusion: Text-to-3D using 2D Diffusion</papertitle>-->
<!--    </a>-->
<!--    <br>-->
<!--    <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>,-->
<!--    <a href="https://www.ajayj.com/">Ajay Jain</a>,-->
<!--    <strong>Jonathan T. Barron</strong>,-->
<!--		<a href="https://bmild.github.io/">Ben Mildenhall</a>-->
<!--    <br>-->
<!--    <em>ICLR</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation, Outstanding Paper Award)</strong></font>-->
<!--    <br>-->
<!--    <a href="https://dreamfusion3d.github.io/">project page</a>-->
<!--    /-->
<!--    <a href="https://arxiv.org/abs/2209.14988">arXiv</a>-->
<!--    /-->
<!--    <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a>-->
<!--    <p></p>-->
<!--    <p>-->
<!--    We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling.-->
<!--    </p>-->
<!--  </td>-->
<!--</tr>-->
<tr onmouseout="hlclip_stop()" onmouseover="hlclip_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='hlclip_image'>
        <img src='images/hlclip.png' width="160"></div>
      <img src='images/hlclip.png' width="160">
    </div>
    <script type="text/javascript">
      function hlclip_start() {
        document.getElementById('hlclip_image').style.opacity = "1";
      }

      function hlclip_stop() {
        document.getElementById('hlclip_image').style.opacity = "0";
      }
      hlclip_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://arxiv.org/abs/2404.01745">
      <papertitle>Unleash the Potential of CLIP for Video Highlight Detection</papertitle>
    </a>
    <br>
    <a href="https://scholar.google.com/citations?hl=en&user=BKlC7TQAAAAJ">Donghoon Han*</a>,
    <strong>Seunghyeon Seo*</strong>,
    Eunhwan Park,
    SeongUk Nam,
    <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>
    <br>
    <em>CVPR</em> 2024 Workshop on Efficient Large Vision Models
    <br>
<!--     <a href="https://shawn615.github.io/flipnerf">project page</a> -->
<!--      / -->
<!--     <a href="https://github.com/shawn615/FlipNeRF">code</a> -->
<!--      / -->
<!--     <a href="https://youtu.be/_XNsRxzaPjw">video</a> -->
<!--      / -->
    <a href="https://arxiv.org/abs/2404.01745">arXiv</a>
    <p></p>
    <p>
      We leverage the pre-trained multimodal model CLIP to achieve state-of-the-art performance in video highlight detection by fine-tuning the encoder and integrating a novel saliency pooling technique.
    </p>
  </td>
</tr>
		
<tr onmouseout="hgnerf_stop()" onmouseover="hgnerf_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='hgnerf_image'>
        <img src='images/hgnerf_after.png' width="160"></div>
      <img src='images/hgnerf_before.png' width="160">
    </div>
    <script type="text/javascript">
      function hgnerf_start() {
        document.getElementById('hgnerf_image').style.opacity = "1";
      }

      function hgnerf_stop() {
        document.getElementById('hgnerf_image').style.opacity = "0";
      }
      hgnerf_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://arxiv.org/abs/2403.10906">
      <papertitle>HourglassNeRF: Casting an Hourglass as a Bundle of Rays for Few-shot Neural Rendering</papertitle>
    </a>
    <br>
    <strong>Seunghyeon Seo</strong>,
    <a href="https://yeonjin-chang.github.io/">Yeonjin Chang</a>,
    <a href="https://natureyoo.github.io/">Jayeon Yoo</a>,
    <a href="https://lifrary.github.io/">Seungwoo Lee</a>,
    <a href="https://scholar.google.com/citations?user=1BOehSUAAAAJ&hl=en&oi=ao">Hojun Lee</a>,
    <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>
    <br>
    Under Review
    <br>
<!--     <a href="https://shawn615.github.io/flipnerf">project page</a> -->
<!--      / -->
<!--     <a href="https://github.com/shawn615/FlipNeRF">code</a> -->
<!--      / -->
<!--     <a href="https://youtu.be/_XNsRxzaPjw">video</a> -->
<!--      / -->
    <a href="https://arxiv.org/abs/2403.10906">arXiv</a>
    <p></p>
    <p>
      We cast an hourglass as an additional training ray, which adaptively regularizes the high-frequency components of the samples, and enhance the integrity of training framework by conceptualizing the hourglass as a bundle of flipped diffuse reflection rays, aligning with the Lambertian assumption.
    </p>
  </td>
</tr>

<tr onmouseout="srtensorf_stop()" onmouseover="srtensorf_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='srtensorf_image'>
        <img src='images/srtensorf_after.png' width="160"></div>
      <img src='images/srtensorf_before.png' width="160">
    </div>
    <script type="text/javascript">
      function srtensorf_start() {
        document.getElementById('srtensorf_image').style.opacity = "1";
      }

      function srtensorf_stop() {
        document.getElementById('srtensorf_image').style.opacity = "0";
      }
      srtensorf_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://arxiv.org/abs/2311.03965">
      <papertitle>Fast Sun-aligned Outdoor Scene Relighting based on TensoRF</papertitle>
    </a>
    <br>
    <a href="https://yeonjin-chang.github.io/">Yeonjin Chang</a>,
    Yearim Kim,
    <strong>Seunghyeon Seo</strong>,
    Jung Yi,
    <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>
    <br>
    <em>WACV</em> 2024
    <br>
<!--     <a href="https://shawn615.github.io/flipnerf">project page</a> -->
<!--      / -->
<!--     <a href="https://github.com/shawn615/FlipNeRF">code</a> -->
<!--      / -->
<!--     <a href="https://youtu.be/_XNsRxzaPjw">video</a> -->
<!--      / -->
    <a href="https://arxiv.org/abs/2311.03965">arXiv</a>
    <p></p>
    <p>
      We simplify outdoor scene relighting for NeRF by aligning with the sun, eliminating the need for environment maps and speeding up the process using a novel cubemap concept within the framework of TensoRF.
    </p>
  </td>
</tr>

<tr onmouseout="concatplexer_stop()" onmouseover="concatplexer_start()">
   <td style="padding:20px;width:25%;vertical-align:middle">
     <div class="one">
       <div class="two" id='concatplexer_image'>
	 <img src='images/concatplexer_after.png' width="160"></div>
       <img src='images/concatplexer_before.png' width="160">
     </div>
     <script type="text/javascript">
       function concatplexer_start() {
	 document.getElementById('concatplexer_image').style.opacity = "1";
       }

       function concatplexer_stop() {
	 document.getElementById('concatplexer_image').style.opacity = "0";
       }
       concatplexer_stop()
     </script>
   </td>
   <td style="padding:20px;width:75%;vertical-align:middle">
     <a href="https://arxiv.org/abs/2308.11199">
       <papertitle>ConcatPlexer: Additional Dim1 Batching for Faster ViTs</papertitle>
     </a>
     <br>
     <a href="https://scholar.google.com/citations?hl=en&user=BKlC7TQAAAAJ">Donghoon Han</a>,
     <strong>Seunghyeon Seo</strong>,
     <a href="https://scholar.google.com/citations?user=2kW3474AAAAJ&hl=en&oi=ao">DongHyeon Jeon</a>,
     <a href="https://scholar.google.com/citations?hl=en&user=-EtUt1wAAAAJ">Jiho Jang</a>,
     <a href="https://scholar.google.com/citations?user=TownIFQAAAAJ&hl=en&oi=ao">Chaerin Kong</a>,
     <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>
     <br>
     <em>NeurIPS</em> 2023 Workshop on Advancing Neural Network Training &nbsp <font color="red"><strong>(Oral)</strong></font>
     <br>
     <a href="https://arxiv.org/abs/2308.11199">arXiv</a>
     <p></p>
     <p>
       We expedite ViT inference by concatenating abstract visual tokens from multiple images along dim=1 and processing them collectively.
     </p>
   </td>
 </tr>
		
<tr onmouseout="flipnerf_stop()" onmouseover="flipnerf_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='flipnerf_image'>
        <img src='images/flipnerf_after.jpg' width="160"></div>
      <img src='images/flipnerf_before.jpg' width="160">
    </div>
    <script type="text/javascript">
      function flipnerf_start() {
        document.getElementById('flipnerf_image').style.opacity = "1";
      }

      function flipnerf_stop() {
        document.getElementById('flipnerf_image').style.opacity = "0";
      }
      flipnerf_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://shawn615.github.io/flipnerf">
      <papertitle>FlipNeRF: Flipped Reflection Rays for Few-shot Novel View Synthesis</papertitle>
    </a>
    <br>
    <strong>Seunghyeon Seo</strong>,
    <a href="https://yeonjin-chang.github.io/">Yeonjin Chang</a>,
    <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>
    <br>
    <em>ICCV</em> 2023
    <br>
    <a href="https://shawn615.github.io/flipnerf">project page</a>
     /
    <a href="https://github.com/shawn615/FlipNeRF">code</a>
     /
    <a href="https://youtu.be/_XNsRxzaPjw">video</a>
     /
    <a href="https://arxiv.org/abs/2306.17723">arXiv</a>
    <p></p>
    <p>
      We utilize the flipped reflection rays as additional training resources for the few-shot novel view synthesis, leading to more accurate surface normal estimation.
    </p>
  </td>
</tr>			
		
<tr onmouseout="mdpose_stop()" onmouseover="mdpose_start()">
   <td style="padding:20px;width:25%;vertical-align:middle">
     <div class="one">
       <div class="two" id='mdpose_image'>
	 <img src='images/mdpose_after.png' width="160"></div>
       <img src='images/mdpose_before.png' width="160">
     </div>
     <script type="text/javascript">
       function mdpose_start() {
	 document.getElementById('mdpose_image').style.opacity = "1";
       }

       function mdpose_stop() {
	 document.getElementById('mdpose_image').style.opacity = "0";
       }
       mdpose_stop()
     </script>
   </td>
   <td style="padding:20px;width:75%;vertical-align:middle">
     <a href="https://arxiv.org/abs/2302.08751">
       <papertitle>MDPose: Real-Time Multi-Person Pose Estimation via Mixture Density Model</papertitle>
     </a>
     <br>
     <strong>Seunghyeon Seo</strong>,
     <a href="https://scholar.google.com/citations?user=xQ2kWlYAAAAJ&hl=en&oi=ao">Jaeyoung Yoo</a>,
     <a href="https://scholar.google.com/citations?hl=en&user=NpivtnsAAAAJ">Jihye Hwang</a>,
     <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>
     <br>
     <em>UAI</em> 2023
     <br>
     <a href="https://arxiv.org/abs/2302.08751">arXiv</a>
     <p></p>
     <p>
       We model the high-dimensional joint distribution of human keypoints with a mixture density model by Random Keypoint Grouping strategy and achieve competitive performance working in real-time by eliminating additional instance identification process.
     </p>
   </td>
 </tr>		
		
<tr onmouseout="drmm_stop()" onmouseover="drmm_start()">
   <td style="padding:20px;width:25%;vertical-align:middle">
     <div class="one">
       <div class="two" id='drmm_image'>
	 <img src='images/drmm_after.jpg' width="160"></div>
       <img src='images/drmm_before.jpg' width="160">
     </div>
     <script type="text/javascript">
       function drmm_start() {
	 document.getElementById('drmm_image').style.opacity = "1";
       }

       function drmm_stop() {
	 document.getElementById('drmm_image').style.opacity = "0";
       }
       drmm_stop()
     </script>
   </td>
   <td style="padding:20px;width:75%;vertical-align:middle">
     <a href="https://arxiv.org/abs/2205.08714">
       <papertitle>End-to-End Multi-Object Detection with a Regularized Mixture Model</papertitle>
     </a>
     <br>
     <a href="https://scholar.google.com/citations?user=xQ2kWlYAAAAJ&hl=en&oi=ao">Jaeyoung Yoo*</a>,
     <a href="https://scholar.google.com/citations?user=1BOehSUAAAAJ&hl=en&oi=ao">Hojun Lee*</a>,
     <strong>Seunghyeon Seo</strong>,
     <a href="https://scholar.google.com/citations?user=6bFY9FgAAAAJ&hl=en&oi=ao">Inseop Chung</a>,
     <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>
     <br>
     <em>ICML</em> 2023
     <br>
     <a href="https://github.com/lhj815/D-RMM">code</a>
     /
     <a href="https://arxiv.org/abs/2205.08714">arXiv</a>
     <p></p>
     <p>
       We propose the end-to-end multi-object Detection with a Regularized Mixture Model (D-RMM), which is trained by minimizing the NLL with the proposed regularization term, maximum component maximization (MCM) loss, preventing duplicate predictions.
     </p>
   </td>
 </tr>
		
<tr onmouseout="mixnerf_stop()" onmouseover="mixnerf_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='mixnerf_image'>
        <img src='images/mixnerf_after.jpg' width="160"></div>
      <img src='images/mixnerf_before.jpg' width="160">
    </div>
    <script type="text/javascript">
      function mixnerf_start() {
        document.getElementById('mixnerf_image').style.opacity = "1";
      }

      function mixnerf_stop() {
        document.getElementById('mixnerf_image').style.opacity = "0";
      }
      mixnerf_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://shawn615.github.io/mixnerf">
      <papertitle>MixNeRF: Modeling a Ray with Mixture Density for Novel View Synthesis from Sparse Inputs</papertitle>
    </a>
    <br>
    <strong>Seunghyeon Seo</strong>,
    <a href="https://scholar.google.com/citations?hl=en&user=BKlC7TQAAAAJ">Donghoon Han*</a>,
    <a href="https://yeonjin-chang.github.io/">Yeonjin Chang*</a>,
    <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>
    <br>
    <em>CVPR</em> 2023 &nbsp <font color="red"><strong>(Qualcomm Innovation Fellowship Korea 2023 Winner)</strong></font>
    <br>
    <a href="https://shawn615.github.io/mixnerf">project page</a>
    /
    <a href="https://github.com/shawn615/MixNeRF">code</a>
    /
    <a href="https://youtu.be/PXljJordbFk">video</a>
    /
    <a href="https://arxiv.org/abs/2302.08788">arXiv</a>
    <p></p>
    <p>
      We model a ray with mixture density model, leading to efficient learning of density distribution with sparse inputs, and propose an effective auxiliary task of ray depth estimation for few-shot novel view synthesis.
    </p>
  </td>
</tr>

<tr onmouseout="mum_stop()" onmouseover="mum_start()">
   <td style="padding:20px;width:25%;vertical-align:middle">
     <div class="one">
       <div class="two" id='mum_image'>
	 <img src='images/mum_after.png' width="160"></div>
       <img src='images/mum_before.png' width="160">
     </div>
     <script type="text/javascript">
       function mum_start() {
	 document.getElementById('mum_image').style.opacity = "1";
       }

       function mum_stop() {
	 document.getElementById('mum_image').style.opacity = "0";
       }
       mum_stop()
     </script>
   </td>
   <td style="padding:20px;width:75%;vertical-align:middle">
     <a href="https://arxiv.org/abs/2111.10958">
       <papertitle>MUM: Mix Image Tiles and UnMix Feature Tiles for Semi-Supervised Object Detection</papertitle>
     </a>
     <br>
     <a href="https://scholar.google.com/citations?user=mknAd9cAAAAJ&hl=en">JongMok Kim</a>,
     <a href="https://scholar.google.com/citations?hl=en&user=ZWNWTicAAAAJ">Jooyoung Jang</a>,
     <strong>Seunghyeon Seo</strong>,
     <a href="https://sites.google.com/view/soo89/">Jisoo Jeong</a>,
     Jongkeun Na,
     <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>
     <br>
     <em>CVPR</em> 2022
     <br>
     <a href="https://github.com/JongMokKim/mix-unmix">code</a>
     /
     <a href="https://arxiv.org/abs/2111.10958">arXiv</a>
     <p></p>
     <p>
       We introduce a simple yet effective data augmentation method, Mix/UnMix (MUM), which unmixes feature tiles for the mixed image tiles for the SSOD framework.
     </p>
   </td>
 </tr>

</tbody></table>

				
<!--        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>-->
<!--          <tr>-->
<!--            <td>-->
<!--              <heading>Misc</heading>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->
<!--        <table width="100%" align="center" border="0" cellpadding="20"><tbody>-->
<!--					-->
<!--          <tr>-->
<!--            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>-->
<!--            <td width="75%" valign="center">-->
<!--              <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>-->
<!--              <br>-->
<!--              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>-->
<!--              <br>-->
<!--              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>-->
<!--              <br>-->
<!--              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>-->
<!--            </td>-->
<!--          </tr>-->
<!--          <tr>-->
<!--            <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--              <img src="images/cs188.jpg" alt="cs188">-->
<!--            </td>-->
<!--            <td width="75%" valign="center">-->
<!--              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>-->
<!--              <br>-->
<!--              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>-->
<!--              <br>-->
<!--              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>-->
<!--            </td>-->
<!--          </tr>-->
<!--					-->

<!--          <tr>-->
<!--            <td align="center" style="padding:20px;width:25%;vertical-align:middle">-->
<!--							<heading>Basically <br> Blog Posts</heading>-->
<!--            </td>-->
<!--            <td width="75%" valign="middle">-->
<!--              <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>-->
<!--              <br>-->
<!--              <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>-->
<!--              <br>-->
<!--              <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>-->
<!--            </td>-->
<!--          </tr>-->
<!--					-->
<!--					-->
<!--        </tbody></table>-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Thanks for sharing the website template, <a href="https://jonbarron.info/">Jon Barron</a>. :)
<!--                Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.-->
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
